{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "999b5f12",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "## (1A) In this exercise you are asked to implement an LSTM model. \n",
    "\n",
    "You may want to have a read of the [LSTM paper](https://www.bioinf.jku.at/publications/older/2604.pdf) but you can also just rely on the equations and ideas presented here.\n",
    "\n",
    "An LSTM is a type of recurrent neural network (RNN) that is designed to overcome the vanishing gradient problem and capture long-term dependencies in sequential data. While a standard RNN has only a hidden state, the LSTM also has a cell state that acts as a gated long-term memory. This can also be interpreted as a kind of skip connections through time - effectively leading to shorter computational graphs when backpropagating through time.\n",
    "\n",
    "### LSTM Components\n",
    "\n",
    "The LSTM unit consists of several components, including:\n",
    "\n",
    "1. Input Gate (i): Controls the flow of information into the cell state.\n",
    "2. Forget Gate (f): Controls the flow of information that should be discarded from the cell state.\n",
    "3. Cell State (C): A memory cell that stores the information over time.\n",
    "4. Output Gate (o): Controls the flow of information from the cell state to the output.\n",
    "5. Hidden State (h): The output of the LSTM cell that carries information to the next time step.\n",
    "\n",
    "### LSTM Equations\n",
    "\n",
    "Let's represent the input at time step t as x(t), the previous hidden state at time step t-1 as h(t-1), the previous cell state at time step t-1 as C(t-1), and the output at time step t as y(t).\n",
    "\n",
    "The LSTM unit performs the following computations at each time step:\n",
    "\n",
    "1. Calculate the input to the LSTM unit (pre-activation):\n",
    "\n",
    "$$z(t) = \\text{concatenate}(x(t), h(t-1))$$\n",
    "\n",
    "2. Compute the forget gate (f) to decide what information to discard from the cell state:\n",
    "\n",
    "$$f(t) = \\sigma(W_f \\cdot z(t) + b_f)$$\n",
    "\n",
    "3. Compute the input gate (i) to decide what new information to store in the cell state:\n",
    "\n",
    "$$i(t) = \\sigma(W_i \\cdot z(t) + b_i)$$\n",
    "\n",
    "4. Calculate the candidate cell state (Äˆ) which is the new information to be added to the cell state:\n",
    "\n",
    "$$\\widetilde{C}(t) = \\tanh(W_C \\cdot z(t) + b_C)$$\n",
    "\n",
    "5. Update the cell state (C) using the forget gate and the input gate:\n",
    "\n",
    "$$C(t) = f(t) \\cdot C(t-1) + i(t) \\cdot \\widetilde{C}(t)$$\n",
    "\n",
    "6. Compute the output gate (o) to decide what information to output from the cell state:\n",
    "\n",
    "$$o(t) = \\sigma(W_o \\cdot z(t) + b_o)$$\n",
    "\n",
    "7. Calculate the hidden state (h) to be carried forward to the next time step:\n",
    "\n",
    "$$h(t) = o(t) \\cdot \\tanh(C(t))$$\n",
    "\n",
    "### Key components\n",
    "\n",
    "- $W_f, W_i, W_C, W_o$ are weight matrices for the forget gate, input gate, candidate cell state, and output gate, respectively.\n",
    "- $b_f, b_i, b_C, b_o$ are bias vectors for the forget gate, input gate, candidate cell state, and output gate, respectively.\n",
    "- $\\sigma$ is the sigmoid activation function, and $\\tanh$ is the hyperbolic tangent activation function.\n",
    "\n",
    "The Matrix multiplications by weights $W_f, W_i, W_C, W_o$ and the biases $b_f, b_i, b_C, b_o$ can be encapsulated in fully connected layers (``tf.keras.layers.Dense``), so you do not need to instantiate the variables yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3478f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
