{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9693d574",
   "metadata": {},
   "source": [
    "# Regularizing a convolutional neural network\n",
    "\n",
    "In this exercise you are asked to train another convolutional neural network on CIFAR100 and this time regularize it using methods of your own choice (feel free to go beyond what was shown in session 09). You may take the same VGG architecture that you used in exercise 04.\n",
    "\n",
    "## Train the network using the compile and fit methods (as seen in session 09), reporting train/validation accuracy and Categorical Crossentropy loss\n",
    "\n",
    "\n",
    "- Before running your experiments, we set the random seed to a fixed value\n",
    "\n",
    "\n",
    "- The training and validation data is already prepared for you\n",
    "\n",
    "\n",
    "- When using dropout or batch normalization, make sure to set the training argument in the call methods of your modules/layers/model, since these layers have a different behavior during test time\n",
    "\n",
    "\n",
    "- If the coefficients for L2 and L1 regularization are too high, the model will not learn. Same for the dropout rate in dropout layers and the strength of data augmentation\n",
    "\n",
    "\n",
    "- If you want to use data augmentation, you will need to modify the data loader like it is done in session 08.\n",
    "\n",
    "\n",
    "- Try different model sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "def get_cifar100(batch_size):\n",
    "    \"\"\"\n",
    "    Load and prepare CIFAR-100 as a tensorflow dataset.\n",
    "    Returns a train and validation dataset.\n",
    "\n",
    "    Args:\n",
    "    batch_size (int)\n",
    "    \"\"\"\n",
    "    train_ds, val_ds = tfds.load('cifar100', split=['train', 'test'], shuffle_files=True)\n",
    "\n",
    "    one_hot = lambda x: tf.one_hot(x, 100)\n",
    "\n",
    "    map_func = lambda x,y: (tf.cast(\n",
    "        tf.expand_dims(x, -1), dtype=tf.float32)/255.,\n",
    "                            tf.cast(one_hot(y),tf.float32))\n",
    "\n",
    "    map_func_2 = lambda x: (x[\"image\"],x[\"label\"])\n",
    "\n",
    "    train_ds = train_ds.map(map_func_2).map(map_func)\n",
    "    val_ds   = val_ds.map(map_func_2).map(map_func)\n",
    "\n",
    "    train_ds = train_ds.shuffle(1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds   = val_ds.shuffle(1024).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return (train_ds, val_ds)\n",
    "\n",
    "train_ds, val_ds = get_cifar100(batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f331ba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
