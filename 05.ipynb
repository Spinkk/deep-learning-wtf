{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b8f1f7",
   "metadata": {},
   "source": [
    "# Keras metrics\n",
    "\n",
    "Instead of appending loss values to a list or a numpy array, when using TensorFlow, we usually rely on something more convenient: tf.keras.metrics objects.\n",
    "\n",
    "Keras comes with useful objects that support tracking a variable, such as the loss over an entire epoch, computing the average over all losses efficiently while allowing for graph mode train and test step functions/methods.\n",
    "\n",
    "\n",
    "Let's assume we have one **epoch** with a small dataset that fills only **4 batches**, so to compute the average loss for this epoch, we want to average over four loss values. \n",
    "\n",
    "We can do this with a tf.keras.metrics.Mean object, which has an **update_state** method, that takes a scalar value to take into account for the running average, a **result** method, to obtain the result, and a **reset_states** method that resets the metric (after an epoch and between the training and validation steps).\n",
    "\n",
    "To see what is going on we print the metric's result after each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b16d1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "loss_function = tf.keras.losses.MeanSquaredError()\n",
    "\n",
    "# instantiate metric object (usually in the model's constructor, i.e. __init__, method)\n",
    "loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "# ITERATING OVER A NUMBER OF EPOCHS:\n",
    "epochs=4\n",
    "for e in range(epochs):\n",
    "\n",
    "    # ITERATING OVER TRAINING DATA\n",
    "    for batch in range(1000):\n",
    "\n",
    "        model_output = tf.random.uniform(shape=(4,1))*10\n",
    "        target = tf.random.uniform(shape=(4,1))*10\n",
    "\n",
    "        loss = loss_function(target, model_output)\n",
    "\n",
    "        loss_metric.update_state(values=loss)\n",
    "\n",
    "    tf.print(f\"Epoch {e}: loss: {loss_metric.result()}\")\n",
    "\n",
    "    # RESETTING THE METRIC BEFORE USING IT FOR VALIDATION\n",
    "    loss_metric.reset_states()\n",
    "\n",
    "    # ITERATING OVER VALIDATION DATA\n",
    "    for batch in range(200):\n",
    "\n",
    "        model_output = tf.random.uniform(shape=(4,1))*10\n",
    "\n",
    "        target = tf.random.uniform(shape=(4,1))*10\n",
    "\n",
    "        val_loss = loss_function(target, model_output)\n",
    "\n",
    "        loss_metric.update_state(values=val_loss)\n",
    "\n",
    "    tf.print(f\"Epoch {e}: val_loss: {loss_metric.result()} \\n\")\n",
    "\n",
    "    # RESETTING THE METRIC BEFORE NEXT EPOCH\n",
    "    loss_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916f95f6",
   "metadata": {},
   "source": [
    "## Accuracy metrics for binary classification\n",
    "As you see we can use tf.keras.metrics.Mean objects to compute running averages without using numpy or list appends. Keras comes with such metric objects for a number of different metrics that we might use to evaluate our model's performance, such as **BinaryAccuracy** in the context of binary classification and **CategoricalAccuracy** **TopKCategoricalAccuracy** in the context of multi-class classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate metric object (usually in the model's constructor, i.e. __init__, method)\n",
    "loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "binary_accuracy_metric = tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "# What happens in one epoch in the training loop:\n",
    "\n",
    "# training on train data (4 batches)\n",
    "epochs=4\n",
    "for e in range(epochs):\n",
    "    for train_batch in range(100):\n",
    "        target = tf.random.uniform(shape=(4,1),minval=0, maxval=1, dtype=tf.int32)\n",
    "        model_output = tf.random.uniform(shape=(4,1))\n",
    "\n",
    "        loss = loss_function(target, model_output)\n",
    "        # \n",
    "        loss_metric.update_state(values=loss)\n",
    "        binary_accuracy_metric.update_state(target, model_output)\n",
    "    tf.print(f\"Epoch {e}: loss: {loss_metric.result()}\")\n",
    "    tf.print(f\"Epoch {e}: accuracy: {binary_accuracy_metric.result()}\")\n",
    "\n",
    "    # RESETTING METRICS BEFORE EVALUATION\n",
    "    loss_metric.reset_states()\n",
    "    binary_accuracy_metric.reset_states()\n",
    "\n",
    "    for val_batch in range(20):\n",
    "        target = tf.random.uniform(shape=(4,1),minval=0, maxval=1, dtype=tf.int32)\n",
    "        model_output = tf.random.uniform(shape=(4,1))\n",
    "\n",
    "        loss = loss_function(target, model_output)\n",
    "        loss_metric.update_state(values=loss)\n",
    "        binary_accuracy_metric.update_state(target, model_output)\n",
    "\n",
    "    tf.print(f\"Epoch {e}: val_loss: {loss_metric.result()}\")\n",
    "    tf.print(f\"Epoch {e}: val_accuracy: {binary_accuracy_metric.result()} \\n\")\n",
    "\n",
    "# resetting the metric before the next epoch\n",
    "loss_metric.reset_states()\n",
    "binary_accuracy_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a7ea86",
   "metadata": {},
   "source": [
    "## Accuracy metrics for multi-class categorization tasks\n",
    "\n",
    "In multi-class classification, we use the **CategoricalCrossentropy** as our loss function. To track the accuracy, we need to use a different keras metric, **CategoricalAccuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acbca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate metric object (usually in the model's constructor, i.e. __init__, method)\n",
    "loss_metric = tf.keras.metrics.Mean(name=\"loss\")\n",
    "accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "for e in range(5):\n",
    "    for train_batch in range(100):\n",
    "        \n",
    "        # create random one-hot targets (labels)\n",
    "        target = tf.one_hot(tf.random.uniform(minval=0,maxval=9, shape=(4,),dtype=tf.int32), depth=10)\n",
    "\n",
    "        # create random model output (for each element in the batch the values are probabilities that sum to 1)\n",
    "        model_output = tf.nn.softmax(tf.random.uniform(shape=(4,10)), axis=-1)\n",
    "\n",
    "        loss = loss_function(target, model_output)\n",
    "\n",
    "        loss_metric.update_state(values=loss)\n",
    "        accuracy_metric.update_state(target, model_output)\n",
    "    tf.print(f\"Epoch {e}: loss: {loss_metric.result()}\")\n",
    "    tf.print(f\"Epoch {e}: accuracy: {accuracy_metric.result()}\")\n",
    "\n",
    "    # RESETTING METRICS BEFORE EVALUATION\n",
    "    loss_metric.reset_states()\n",
    "    accuracy_metric.reset_states()\n",
    "\n",
    "    for val_batch in range(20):\n",
    "        target = tf.one_hot(tf.random.uniform(minval=0,maxval=9, shape=(4,),dtype=tf.int32), depth=10)\n",
    "        model_output = tf.nn.softmax(tf.random.uniform(shape=(4,10)), axis=-1)\n",
    "\n",
    "        loss = loss_function(target, model_output)\n",
    "        loss_metric.update_state(values=loss)\n",
    "        accuracy_metric.update_state(target, model_output)\n",
    "\n",
    "    tf.print(f\"Epoch {e}: val_loss: {loss_metric.result()}\")\n",
    "    tf.print(f\"Epoch {e}: val_accuracy: {accuracy_metric.result()} \\n\")\n",
    "\n",
    "    # resetting the metric before the next epoch\n",
    "    loss_metric.reset_states()\n",
    "    accuracy_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16109009",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- We can use keras metrics instead of tedious numpy loss tracking and metric computations. \n",
    "\n",
    "- Keras metrics can be used with Tensorflow's graph mode, while list appends and numpy operations generally can not\n",
    "\n",
    "- The convenient compile and fit methods of the tf.keras.Model class use keras metrics under the hood. \n",
    "    - Starting to use the metric objects gets us a step closer to being able to use these tools.\n",
    "\n",
    "\n",
    "Next: **Tensorboard for logging**, log all possible kinds of training data to the tensorboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
