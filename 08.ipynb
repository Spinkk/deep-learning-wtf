{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c768be0",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "There is no better way to get an introduction to convolutional layers than with an interactive widget that you can explore to see what the calculation looks like.\n",
    "\n",
    "Images and other 2D feature maps in TensorFlow are represented as tensors of shape (B, H, W, C) where B is the batch size, H is the height, W is the width and C is the number of channels or feature maps.\n",
    "\n",
    "**Try to answer the following questions as detailed as possible by playing with the parameters of the widget and observing the consquences**:\n",
    "\n",
    "- How does the kernel size affect the number of parameters?\n",
    "\n",
    "\n",
    "- How does the number of filters affect the number of parameters?\n",
    "\n",
    "\n",
    "- How does the kernel size affect the height and width of the resulting feature maps?\n",
    "\n",
    "\n",
    "- How does that change when padding is set to \"same\" instead of \"valid\"?\n",
    "\n",
    "\n",
    "- What does strides do and how does it affect the output shape?\n",
    "\n",
    "\n",
    "- How are different feature maps mixed with each other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6ccd6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"800\"\n",
       "            src=\"https://spinkk.github.io/tensorflow_convolution_widget.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1e48fba0eb0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='https://spinkk.github.io/tensorflow_convolution_widget.html', width=1000, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c612111",
   "metadata": {},
   "source": [
    "# Different interpretations of convolutional inductive biases\n",
    "\n",
    "An inductive bias, that is a restriction of or preference for certain solutions to the modeling problem, that convolutional layers introduce to a model is to share weights across the spatial structure of their input or representations.\n",
    "\n",
    "You can think of convolutions as sliding a filter template over feature maps, computing the correlation of the filter templates with the feature map contents at each feature map location. The output of a convolutional layer can thus be read as values indicating how similar the kernel weights (the convolutional filter) is with the input at that location. In fact, convolutions compute the dot product between the filter and the input, which is the highest if the spatial structure of both kernel and signal are identical (a template is found to match the input). While this is a nice and intuitive interpretation of convolutional layers in ANNs, it is certainly an oversimplification. The convolution operation also involves linearly combining different feature maps into a new single feature map per filter.\n",
    "\n",
    "Another perspective from which to view convolutional layers can be unlocked by comparing them to linear or dense/fully connected layers. For a kernel size that is the same as the input size, a convolutional layer ends up being equivalent to a fully connected layer, where the number of filters becomes the number of units (try it in the interactive widget!). Once we decrease the kernel size, we end up with spatial weight sharing, that is, we have fewer parameters than in the case where we flatten the feature maps and have a fully connected layer that takes the resulting vector as its input. From this perspective, convolutional layers introduce weight sharing that acts in a regularizing way. Indeed convolutional architectures lead to less overfitting than fully connected architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2c0ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa0b8021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape: (32, 64, 64, 12)\n",
      "number of parameters: 1740\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tf.random.normal((32,64,64,16))\n",
    "\n",
    "layer = tf.keras.layers.Conv2D(filters=12,\n",
    "                               kernel_size=(3,3),\n",
    "                               strides=(1,1),\n",
    "                               padding=\"same\")\n",
    "\n",
    "print(\"output shape:\", layer(input_tensor).shape)\n",
    "print(\"number of parameters:\", layer.trainable_variables[0].numpy().size+layer.trainable_variables[1].numpy().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e4ef39",
   "metadata": {},
   "source": [
    "# Pooling operations\n",
    "\n",
    "An operation that is often used in conjunction with convolutional layers is pooling layers. A pooling layer can be thought of as a convolution in the sense that it performs a similar sliding filtering. Instead of a convolution however it uses a rank filter, e.g. a mean filter for average pooling, or a max filter for max pooling.\n",
    "\n",
    "If the kernel size for the pooling is set to the size of the input feature maps, we call this global pooling, which practically reduces a number n of 2D feature maps to an n-dimensional vector - each feature map was reduced to a single number, either its mean or its maximum.\n",
    "\n",
    "Pooling layers do not have any trainable variables. They can however contribute to inductive biases such as increased translation invariance (that is the same object present in different places in a scene leads to the same representations).\n",
    "\n",
    "In convolutional architectures, global average pooling is preferred over flattening feature maps before feeding the resulting vector to a fully connected layer that does classification. The reason is that the resulting dimensionality is much smaller and thus the fully connected layer will have fewer weights, leading to less overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9686d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output shape (max pool): (32, 32, 32, 16)\n",
      "output shape (global avg pool): (32, 16)\n"
     ]
    }
   ],
   "source": [
    "input_tensor = tf.random.normal((32,64,64,16))\n",
    "pooling_layer = tf.keras.layers.MaxPool2D(pool_size=(2,2))\n",
    "print(\"output shape (max pool):\", pooling_layer(input_tensor).shape)\n",
    "\n",
    "global_pooling_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "print(\"output shape (global avg pool):\", global_pooling_layer(input_tensor).shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
