# Teaching TensorFlow

This is a compiled repository of my teaching material from teaching a course on deep learning with TensorFlow in 2021/22 and 2022/23 and is meant as a self-contained resource for self-study. 

Sessions 12, 14 and 15 as well as homework assignments are not yet available in this repository for independent learning purposes. They will be added when I find time to add the content.

## Course contents:

- 00 Basic tensor operations in TensorFlow


- 01 From biological neurons to logic gates, to activation functions to universal function approximation (build your first ANN from scratch)


- 02 Learning in ANNs: Gradient Descent, Backpropagation, and Automatic Differentiation (build your first ANN from scratch, including backpropagation and training loop)


- 03 Basic usage of TensorFlow's automatic differentiation: The GradientTape context manager


- 04 Modules, Layers, and Models. An introduction to the Keras Subclassing API


- 05 Keras metrics for keeping track of losses, accuracies etc.


- 06 Loss functions and optimizers


- 07 Putting it together: Using TensorBoard to log training data and implementing a subclassed model using keras metrics and a custom training loop.


- 08 Convolutional Neural Networks (incl. interactive widget)


- 09 Regularization: Avoiding overfitting with L1/L2 penalties, dropout, normalization and data augmentation


- 10 Optimization difficulties: Vanishing and exploding gradients. Weight initialization, normalization and residual/skip connections as partial solutions


- 11 Recurrent Neural Networks: From unrolled recurrence to dynamically unrolled custom recurrent cells


- (12 Autoencoders)


- 13 Generative Models


- (14. Transformers and NLP)


- (15. Deep Reinforcement Learning)
